{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# FACS Analysis\n",
    "\n",
    "This Jupyter notebook walks you through the basic steps of analyzing Mass-Titr FACS results. For high-throughput binding experiments, the `highThroughputScripts` pipeline is available on [GitHub](https://github.com/KeatingLab/highThroughputScripts/tree/vs_optimization).\n",
    "\n",
    "To complete the analysis, run all cells in order one-by-one unless otherwise specified, filling in or changing input values as needed. (Hint: Use `Shift+Enter` to run a cell then advance to the next one.) To export a plot, you may want to change the DPI in the `plt.figure` command, i.e. `plt.figure(..., dpi=160)`.\n",
    "\n",
    "**Requirements**: This notebook requires Python, and the following modules:\n",
    "\n",
    "* `FlowCytometryTools` (install using `pip install flowcytometrytools`)\n",
    "* `lmfit`\n",
    "* `ipywidgets`, version 7.2 or later (upgrade if necessary)\n",
    "* The script `facs_utils.py` must be in the same directory as this notebook.\n",
    "\n",
    "After installing these modules, be sure to restart the notebook kernel to make sure the modules are available.\n",
    "\n",
    "*Written by*: Venkatesh Sivaraman, February 2019, adapted from scripts by Dustin Whitney and Theresa Hwang<br>\n",
    "*Modified by*: Jackson Halpin, April 2021"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Experiment metadata\n",
    "# Name:\n",
    "# Date:\n",
    "# Info:"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import os\n",
    "from FlowCytometryTools import FCMeasurement\n",
    "from FlowCytometryTools import ThresholdGate, PolyGate\n",
    "import pandas as pd \n",
    "from lmfit import Model, Parameters, Minimizer\n",
    "import facs_utils as facs\n",
    "from collections import OrderedDict\n",
    "from FlowCytometryTools.core.transforms import hlog"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Dictionary that contains gating information (rerun this cell to reset interactive gate info)\n",
    "GATE_RESULTS = {}\n",
    "\n",
    "# Boundary value for hyperlog transformation\n",
    "HYPERLOG_B = 100.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 0. Preliminaries\n",
    "\n",
    "First we need to provide some information about the experiment, and point the script to where the data is located."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Path to directory containing .fcs files\n",
    "DATA_PATH = \"../data/\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define and label your titrations here, along with the concentrations at which the experiment was performed. \n",
    "\n",
    "Because there are many different methods of plate organization and file naming, you must use the `make_titration` function to tell the script which fcs files to draw data from for each titration. The function takes as parameters the **specimen number**, the **letter code**, and the **number code** for each stop. Each parameter can also be a list, range, or string whose length is the number of concentrations. *Remember that the `range` function's upper bound is non-inclusive, so `range(1, 13)` produces the values [1,2,...,12].*\n",
    "\n",
    "**Examples:**\n",
    "* For the command `make_titration(1, 'ABCDEFGH', 1)`, the following wells from Specimen 1 will be used: A1, B1, C1, D1, E1, F1, G1, H1.\n",
    "* For the command `make_titration(2, 'B', range(1, 7)`, wells B1-B6 prefixed with Specimen 2 will be used."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "CONCENTRATIONS = np.array([15, 7.5, 3.75, 1.875, 0.9375, 0.46875, 0.234375, 0])\n",
    "\n",
    "TITRATIONS = [\n",
    "    # The behavior implemented here is to divide each letter code into two sets (1-6 and 7-12),\n",
    "    # each of which constitutes one titration. Adjust this as needed based on your \n",
    "    # experimental setup.\n",
    "    facs.make_titration(3, 'B', range(1, 9)),\n",
    "    facs.make_titration(4, 'C', range(1, 9)),\n",
    "    facs.make_titration(5, 'D', range(1, 9)),\n",
    "]\n",
    "\n",
    "# Add a descriptive label here for each titration you listed above (e.g. indicate the peptide being tested).\n",
    "LABELS = [\n",
    "    \"peptide-1\", \"peptide-2\", \"peptide-3\"\n",
    "]\n",
    "\n",
    "assert all([len(t) == len(CONCENTRATIONS) for t in TITRATIONS]), \"All titrations must have same number of concentrations as CONCENTRATIONS list\"\n",
    "assert len(LABELS) == len(TITRATIONS), \"Need {} labels to match titrations list, found {}\".format(len(TITRATIONS), len(LABELS))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Defining axes for various types of gates\n",
    "scatter_axes_1 = [\"FSC-H\", \"SSC-H\"]\n",
    "scatter_axes_2 = [\"SSC-H\", \"SSC-W\"]\n",
    "fluor_axes = [\"Alexa Fluor 680-A\", \"PE-A\"]\n",
    "\n",
    "# These axes can be hyperlog-transformed if specified\n",
    "transformable_axes = [\"FSC-H\", \"SSC-H\", \"SSC-W\", \"Alexa Fluor 680-A\", \"PE-A\"]\n",
    "\n",
    "# Binding axis\n",
    "binding_axis = \"PE-A\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Utility functions to get sample paths and data\n",
    "\n",
    "def get_titration_files(titration):\n",
    "    \"\"\"Returns the list of fcs files in DATA_PATH corresponding to the given list of concentration stops.\"\"\"\n",
    "    return [get_sample_path(*stop) for stop in titration]\n",
    "\n",
    "def get_sample_path(specimen_number, letter, sample_number):\n",
    "    \"\"\"Gets the path for the sample with the given specimen number, letter code, and sample number for the letter code.\"\"\"\n",
    "    prefix = 'Specimen_' + str(specimen_number).zfill(3) + '_' + letter + str(sample_number) + '_'\n",
    "    \n",
    "    paths = [os.path.join(DATA_PATH, path) for path in os.listdir(DATA_PATH) if path.startswith(prefix)]\n",
    "    assert len(paths) > 0, \"No path found for ({}, {}, {})\".format(specimen_number, letter, sample_number)\n",
    "    assert len(paths) == 1, \"Multiple paths satisfy sample path condition\"\n",
    "    return paths[0]\n",
    "\n",
    "   \n",
    "def get_sample(path, id_name, transform=False):\n",
    "    \"\"\"Gets a measurement from the given fcs file path, transforming its scatter values using a hyperlog \n",
    "    transformation if specified.\"\"\"\n",
    "    sample = FCMeasurement(ID=id_name, datafile=path)\n",
    "    if transform:\n",
    "        return facs.transform_sample(sample, HYPERLOG_B=HYPERLOG_B)# WARNING HYPERLOG_B is global\n",
    "    return sample"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1. Forward-Scatter and Side-Scatter Gating - **choose 1(a) or 1(b)**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get sample files to test the scatter gates on\n",
    "\n",
    "test_files = get_titration_files(TITRATIONS[0])\n",
    "test_samples = [get_sample(path, \"Test\", transform=True) for path in test_files]\n",
    "\n",
    "test_file = test_files[0]\n",
    "test_sample = test_samples[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1(a). Drawing Gates\n",
    "**NOTE**: The following two cells utilize the interactive gate drawing tool, the first to draw a gate on the FSC-H/SSC-H plot, and the second to gate the SSC-H/SSC-W plot. If no polygon gate is desired, simply skip over the cell without running it. Alternatively, if you already know the vertices for the desired gates, skip to section 1(b) and replace the value of either `gate_vertices_1` or `gate_vertices_2` with the list of coordinates you want."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Choose the number of vertices to use on the gate.\n",
    "num_points = 3\n",
    "\n",
    "# Opens the interactive gate drawing tool.\n",
    "# Use test_samples to plot all 'A' samples together, or test_sample to plot just the first sample (may be faster).\n",
    "facs.vertex_control(test_samples, scatter_axes_1, num_points, GATE_RESULTS, 'scatter_gate_1', log=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Choose the number of vertices to use on the second gate.\n",
    "num_points = 4\n",
    "\n",
    "# Opens the interactive gate drawing tool.\n",
    "# Use test_samples to plot all 'A' samples together, or test_sample to plot just the first sample (may be faster).\n",
    "facs.vertex_control(test_samples, scatter_axes_2, num_points, GATE_RESULTS, 'scatter_gate_2', log=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1(b). Defining the Gates"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Creates the main scatter gate using the interactive results. Set the gate_vertices variables to None \n",
    "# if no polygon gate is desired.\n",
    "gate_vertices_1 = GATE_RESULTS.get('scatter_gate_1', None)\n",
    "gate_vertices_2 = GATE_RESULTS.get('scatter_gate_2', None)\n",
    "if gate_vertices_1 is not None:\n",
    "    print(\"Gate 1 will be created with vertices: {}\".format([tuple(row) for row in gate_vertices_1]))\n",
    "if gate_vertices_2 is not None:\n",
    "    print(\"Gate 2 will be created with vertices: {}\".format([tuple(row) for row in gate_vertices_2]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**If you think that you might need to reprocess your data repeatedly**, I would recommend copy/pasting the vertices that were printed out in the previous cell into the `gate_vertices_1` and `gate_vertices_2` variables below. Then you do not need to re-execute the above cell<br>\n",
    "It makes it much easier to re-run the analysis if you don't have to adjust the gates every time"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# You can use manually defined gates if you uncomment the 2 following lines and replace the \n",
    "# current vertices with your own gate vertices\n",
    "# gate_vertices_1 = [(8270.0, 9125.0), (6295.0, 8875.0), (7670.0, 8625.0), (9890.0, 8640.0), (9950.0, 9095.0)]\n",
    "# gate_vertices_2 = [(9030.0, 7060.0), (8755.0, 7385.0), (8705.0, 4340.0), (9060.0, 4175.0)]\n",
    "scatter_gates = []\n",
    "\n",
    "if gate_vertices_1 is not None:\n",
    "    scatter_gates.append(PolyGate(gate_vertices_1, scatter_axes_1, region='in', name='scatter_gate_1'))\n",
    "    print(\"Gate 1 created with vertices: {}\".format([tuple(row) for row in gate_vertices_1]))\n",
    "if gate_vertices_2 is not None:\n",
    "    scatter_gates.append(PolyGate(gate_vertices_2, scatter_axes_2, region='in', name='scatter_gate_2'))\n",
    "    print(\"Gate 2 created with vertices: {}\".format([tuple(row) for row in gate_vertices_2]))\n",
    "    \n",
    "if gate_vertices_1 is None and gate_vertices_2 is None:\n",
    "    print(\"No polygon gates will be used.\")\n",
    "\n",
    "# Optionally, create some threshold gates to further filter the data.\n",
    "scatter_threshold_gates = [\n",
    "    # ThresholdGate(0, 'FSC-H', region='above'),\n",
    "    # ThresholdGate(9000, 'SSC-H', region='below'),\n",
    "    # ThresholdGate(300, 'SSC-H', region='above')\n",
    "]\n",
    "\n",
    "gates_to_show1 = [x for x in scatter_gates + scatter_threshold_gates if all([c in scatter_axes_1 for c in x.channels])]\n",
    "gates_to_show2 = [x for x in scatter_gates + scatter_threshold_gates if all([c in scatter_axes_2 for c in x.channels])]\n",
    "\n",
    "\n",
    "def gate_by_scatter(sample):\n",
    "    \"\"\"Gates the given FCMeasurement using the scatter_gate and the list of scatter_threshold_gates. \n",
    "    Returns the new gated sample.\"\"\"\n",
    "    tsample = sample\n",
    "    for gate in scatter_gates + scatter_threshold_gates:\n",
    "        tsample = tsample.gate(gate)\n",
    "    return tsample"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ==============================================================================\n",
    "# // check gates against all plots (overlaid) within a titration \n",
    "# ==============================================================================\n",
    "\n",
    "def gate_check(sample_list, scatter_axis, same_lims=True, gate = None, ax=None):\n",
    "#     plt.figure()\n",
    "    maxes = []\n",
    "    for sample in sample_list:\n",
    "        sample.plot(scatter_axis, gates=gate, ax=ax)\n",
    "        maxes.append(sample[scatter_axis].max().max())\n",
    "    if same_lims:\n",
    "        ax_lim = max(maxes)*1.1\n",
    "        plt.xlim(xmax=ax_lim)\n",
    "        plt.ylim(ymax=ax_lim)\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "for titration in TITRATIONS:\n",
    "    test_files = get_titration_files(titration)\n",
    "    test_samples = [get_sample(path, \"Test\", transform=True) for path in test_files]\n",
    "    fig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=[7,3.5])\n",
    "    gate_check(test_samples, scatter_axes_1, gate = gates_to_show1, ax = ax1)\n",
    "    gate_check(test_samples, scatter_axes_2, gate = gates_to_show2, ax = ax2)\n",
    "    plt.tight_layout()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "facs.multi_plots_files(get_titration_files(TITRATIONS[0]), axes=scatter_axes_1, log=False, gates = gates_to_show1, transform=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "facs.multi_plots_files(get_titration_files(TITRATIONS[0]), axes=scatter_axes_2, log=False, gates = gates_to_show2, transform=True)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2. Fluorescence Gating"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def overlay_plt(sample_list, scatter_axis, same_lims=True, gate = None, ax=None):\n",
    "    maxes = []\n",
    "    for sample in sample_list:\n",
    "        sample.plot(scatter_axis, gates=gate, ax=ax, kind='scatter', color='r', s=1)\n",
    "        maxes.append(sample[scatter_axis].max().max())\n",
    "    if same_lims:\n",
    "        ax_lim = max(maxes)*1.1\n",
    "        plt.xlim(xmax=ax_lim)\n",
    "        plt.ylim(ymax=ax_lim)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Gate the test samples from above\n",
    "fluor_samples = [gate_by_scatter(samp) for samp in test_samples]\n",
    "fluor_sample = fluor_samples[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Take a look at the first sample, and all the samples\n",
    "plt.figure()\n",
    "fluor_sample.plot(fluor_axes, ax=plt.gca(), kind='scatter', color='r', s=1);\n",
    "plt.figure()\n",
    "overlay_plt(fluor_samples, fluor_axes, same_lims=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Defining gates\n",
    "I am choosing to do threshold gates for the fluorescence signals. You can look at Venkat's script if you would like to use polygon gates"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Enter the Alexa Fluor 680-A threshold. We will be keeping only data that is above threshold value\n",
    "EXPRESSION_THRESHOLD = 2000"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create some threshold gates to further filter the data.\n",
    "fluor_threshold_gates = [\n",
    "    # ThresholdGate(, 'PE-A', region = 'above'),\n",
    "    ThresholdGate(EXPRESSION_THRESHOLD, 'Alexa Fluor 680-A', region = 'above'),\n",
    "]\n",
    "\n",
    "def gate_by_fluorescence(sample):\n",
    "    \"\"\"Gates the given FCMeasurement using the fluor_gate and the list of fluor_threshold_gates. \n",
    "    Returns the new gated sample.\"\"\"\n",
    "    tsample = sample\n",
    "    for gate in fluor_threshold_gates:\n",
    "        tsample = tsample.gate(gate)\n",
    "    return tsample"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gates_to_show = fluor_threshold_gates\n",
    "for titration in TITRATIONS:\n",
    "    test_files = get_titration_files(titration)\n",
    "    test_samples = [get_sample(path, \"Test\", transform=True) for path in test_files]\n",
    "    fluor_samples = [gate_by_scatter(samp) for samp in test_samples]\n",
    "    plt.figure()\n",
    "    overlay_plt(fluor_samples, fluor_axes, gate = gates_to_show)\n",
    "    plt.tight_layout()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "gates_to_show = fluor_threshold_gates\n",
    "for titration in TITRATIONS:\n",
    "    test_files = get_titration_files(titration)\n",
    "    test_samples = [get_sample(path, \"Test\", transform=True) for path in test_files]\n",
    "    fluor_samples = [gate_by_scatter(samp) for samp in test_samples]\n",
    "    facs.multi_plots_sample(fluor_samples, axes=fluor_axes, log=False, gates = gates_to_show)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3. $K_d$ Estimation\n",
    "\n",
    "Up until now we have only been working with a small subset of the data - now, we will perform the analysis on all samples. \n",
    "\n",
    "**A note on transformations:** All of the gates we have created are in hyperlog-space, so this script is careful to apply any gates in that space. The best practice for fitting, however, is usually to perform the fit on linear (un-transformed) medians. If the `linear_medians` variable below is set to `True`, the median of the un-transformed data will be used (still gated in log space); otherwise, the median of the transformed data will be used."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# If this is set to True, we will use the untransformed data to get the medians; \n",
    "# otherwise, we use the log-transformed data\n",
    "linear_medians = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TODO - change to one of the pandas methods I used in `../04-2021-03-02-single_clone_titration-3/01.ipynb`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get the medians of every gated sample\n",
    "medians = np.zeros((len(TITRATIONS), len(CONCENTRATIONS)))\n",
    "\n",
    "for i, titration in enumerate(TITRATIONS):\n",
    "    for j, sample_info in enumerate(titration):\n",
    "        # Get the path for this sample\n",
    "        path = get_sample_path(*sample_info)\n",
    "        id_name = os.path.splitext(os.path.basename(path))[0]\n",
    "\n",
    "        # Load the sample and gate it\n",
    "        sample = get_sample(path, id_name, transform=False)\n",
    "        tsample = facs.transform_sample(sample, HYPERLOG_B = HYPERLOG_B)\n",
    "        filtered_tsample = gate_by_fluorescence(gate_by_scatter(tsample))\n",
    "        filtered_sample_data = sample.get_data().loc[filtered_tsample.get_data().index]\n",
    "\n",
    "        # Compute median of binding axis values\n",
    "        if linear_medians:\n",
    "            medians[i, j] = filtered_sample_data[binding_axis].median()\n",
    "        else:\n",
    "            medians[i, j] = filtered_tsample.data[binding_axis].median()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot the medians\n",
    "# this is really messy but it wasn't worth the time investment to transfer what was there\n",
    "# titration_to_plot = 1\n",
    "for c,titration in enumerate(TITRATIONS):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    previous_axes = []\n",
    "    xmin, xmax, ymin, ymax = 1e9, -1e9, 1e9, -1e9\n",
    "    for sample_num, sample_info in enumerate(titration):\n",
    "        # Get the path for this sample\n",
    "        path = get_sample_path(*sample_info)\n",
    "        id_name = os.path.splitext(os.path.basename(path))[0]\n",
    "        median = medians[c, sample_num]\n",
    "\n",
    "        # Load the sample and gate it\n",
    "        sample = get_sample(path, id_name, transform=True)\n",
    "        filtered_sample = gate_by_fluorescence(gate_by_scatter(sample))\n",
    "\n",
    "        # Plot\n",
    "        plt.subplot(2, int(ceil(len(CONCENTRATIONS) / 2.0)), sample_num + 1)\n",
    "        filtered_sample.plot(fluor_axes, ax=plt.gca(), kind='scatter', color='r', s=1)\n",
    "        # The median should be hlog-transformed for display if it's on a linear scale\n",
    "        plt.hlines(hlog(median, b=HYPERLOG_B) if linear_medians else median, *plt.xlim(), color='b')\n",
    "        plt.title(id_name)\n",
    "\n",
    "        # Adjust limits\n",
    "        previous_axes.append(plt.gca())\n",
    "        new_xmin, new_xmax = plt.xlim()\n",
    "        new_ymin, new_ymax = plt.ylim()\n",
    "        xmin = min(new_xmin, xmin)\n",
    "        xmax = max(new_xmax, xmax)\n",
    "        ymin = min(new_ymin, ymin)\n",
    "        ymax = max(new_ymax, ymax)\n",
    "        for ax in previous_axes:\n",
    "            ax.set_xlim(xmin, xmax)\n",
    "            ax.set_ylim(ymin, ymax)    \n",
    "    plt.tight_layout()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Now we compute all the Kds. \n",
    "# Initial parameters: (change these parameters depending on what units your concentrations are in. If the fits look wrong, try adjusting these parameters)\n",
    "init_lower = 0\n",
    "init_upper = 4000\n",
    "init_kd = 1\n",
    "max_kd = 40000 # maximum allowed Kd for fitting procedure (setting bounds on fit helps)\n",
    "plot_fits = True\n",
    "\n",
    "# List of dictionaries of fit results\n",
    "fit_results = []\n",
    "\n",
    "if plot_fits: plt.figure(figsize=(20, 5))\n",
    "for i, (label, titration, dataset) in enumerate(zip(LABELS, TITRATIONS, medians)):\n",
    "\n",
    "    if plot_fits:\n",
    "        plt.subplot(int(ceil(len(TITRATIONS) / 4.0)), 4, i + 1)\n",
    "\n",
    "    # Compute fit and save to results dictionary\n",
    "    kd, sat, init, err, chisqr, r2 = facs.run_lmfit(CONCENTRATIONS, dataset, init_lower, init_upper, init_kd, max_kd=max_kd, graph=plot_fits)\n",
    "    result = [(\"label\", label), \n",
    "              (\"kd\", kd), (\"sat\", sat), (\"init\", init),\n",
    "              (\"err\", err), (\"chisqr\", chisqr), (\"r2\", r2)]\n",
    "    for conc, val in zip(CONCENTRATIONS, dataset):\n",
    "        result.append((\"conc_{}\".format(conc), val))\n",
    "    fit_results.append(OrderedDict(result))\n",
    "\n",
    "    if plot_fits:\n",
    "        plt.title(\"{} (Kd = {:.3g})\".format(label, kd))\n",
    "            \n",
    "if plot_fits:\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Build a dataframe from the results list\n",
    "results_df = pd.DataFrame(fit_results)\n",
    "results_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Choose an output path, and write out to CSV\n",
    "out_path = \"kd_list.csv\"\n",
    "results_df.to_csv(out_path, index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Execute the cell below if you want to generate an html report of this notebook in the current directory"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!jupyter nbconvert --to html facs_analysis.ipynb"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}